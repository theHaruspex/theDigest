<h1>
<meta charset="utf-8">
 AI: a Reason to Worry, and to Donate
</h1>
<h2>
</h2>
<i>
 Published December 10, 2017 on Put A Number On It!.
</i>
<div class="entry-content">
 <p>
 </p>
 <p>
  Part of the reason I wrote that
  <a href="https://putanumonit.com/2017/12/04/what-if-were-right/" rel="noopener" target="_blank">
   we’re probably as worried as we should be
  </a>
  about climate change is to learn from my readers’ best objections. To be honest, I am somewhat disappointed by the effort so far.
  <a href="https://putanumonit.com/2017/12/04/what-if-were-right/#comment-2729" rel="noopener" target="_blank">
   dreeves
  </a>
  argued in favor of a carbon tax, but both I and
  <a href="https://www.carbontax.org/polls/" rel="noopener" target="_blank">
   the median
  </a>
  <a href="https://www.usnews.com/news/articles/2014/07/21/most-americans-support-carbon-tax-when-revenue-is-earmarked" rel="noopener" target="_blank">
   American
  </a>
  are basically in agreement already. No one wrote anything that would challenge the “close to the median on the non-worry side” position besides
  <a class="" href="https://putanumonit.com/2017/12/04/what-if-were-right/#comment-2731" rel="noopener" target="_blank">
   shakeddown
  </a>
  , but I haven’t seen too much evidence for his two assertions:
 </p>
 <ol>
  <li>
   That the economic cost of climate change action is small.
  </li>
  <li>
   That the chance of mass extinction due to climate change is nontrivial.
  </li>
 </ol>
 <p>
  Left-leaning CNBC
  <a href="https://www.cnbc.com/id/100398076" rel="noopener" target="_blank">
   quoted the economic cost
  </a>
  of fighting climate change in the US as 2-4% of GDP. That could well be worth every penny, but it’s not a small amount. It also suggests that we might start seeing diminishing returns on the next billion dollars of effort.
 </p>
 <p>
  On the other hand, there’s a looming disaster with a decent chance of wiping out humanity that we’re currently dedicating
  <a href="http://acritch.com/gdp-on-hlai-alignment/" rel="noopener" target="_blank">
   0.00001% of world GDP
  </a>
  to addressing. That’s 3% of what Americans alone spend on Halloween costumes
  <a href="http://mentalfloss.com/article/31222/numbers-how-americans-spend-their-money" rel="noopener" target="_blank">
   for their pets
  </a>
  . If you want to direct your marginal dollars towards saving humankind from annihilation, rather than towards saving dogkind from seasonal unfashionableness, I would encourage you to join me in donating to artificial intelligence alignment research.
 </p>
 <p>
  <img alt="dog-halloween-costumes-raptor.jpg" class="aligncenter size-full wp-image-28450" data-attachment-id="28450" data-comments-opened="1" data-image-description="" data-image-meta='{"aperture":"10","credit":"","camera":"Canon EOS-1Ds Mark II","caption":"","created_timestamp":"1278765197","copyright":"","focal_length":"85","iso":"100","shutter_speed":"0.008","title":"","orientation":"1"}' data-image-title="dog-halloween-costumes-raptor" data-large-file="https://putanumonit.files.wordpress.com/2017/12/dog-halloween-costumes-raptor.jpg?w=900" data-medium-file="https://putanumonit.files.wordpress.com/2017/12/dog-halloween-costumes-raptor.jpg?w=300" data-orig-file="https://putanumonit.files.wordpress.com/2017/12/dog-halloween-costumes-raptor.jpg" data-orig-size="4608,3108" data-permalink="https://putanumonit.com/2017/12/10/worried-about-ai/dog-halloween-costumes-raptor/" sizes="(max-width: 900px) 100vw, 900px" src="https://putanumonit.files.wordpress.com/2017/12/dog-halloween-costumes-raptor.jpg?w=900" srcset="https://putanumonit.files.wordpress.com/2017/12/dog-halloween-costumes-raptor.jpg?w=900 900w, https://putanumonit.files.wordpress.com/2017/12/dog-halloween-costumes-raptor.jpg?w=1800 1800w, https://putanumonit.files.wordpress.com/2017/12/dog-halloween-costumes-raptor.jpg?w=150 150w, https://putanumonit.files.wordpress.com/2017/12/dog-halloween-costumes-raptor.jpg?w=300 300w, https://putanumonit.files.wordpress.com/2017/12/dog-halloween-costumes-raptor.jpg?w=768 768w, https://putanumonit.files.wordpress.com/2017/12/dog-halloween-costumes-raptor.jpg?w=1024 1024w"/>
 </p>
 <hr/>
 <p>
  The
  <a href="https://putanumonit.com/2016/04/27/more-power-less-poverty/" rel="noopener" target="_blank">
   last time we raised money
  </a>
  for a cause I believed in, I wrote it up myself. But there are so many great resources explaining AI alignment that I don’t want to get in the way.
 </p>
 <p>
  If you don’t have all day, you can read a
  <a href="https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html" rel="noopener" target="_blank">
   <span style="color:#993300;">
    blog post with stick figure drawings
   </span>
  </a>
  , or a
  <a href="https://aisafety.wordpress.com/" rel="noopener" target="_blank">
   <span style="color:#993300;">
    blog post with childhood photos
   </span>
  </a>
  . If you have all day,
  <a href="https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom-ebook/dp/B00LOOCGB2/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=" rel="noopener" target="_blank">
   <span style="color:#993300;">
    you can read the book
   </span>
  </a>
  . If you have just 14 minutes and also want to see a person who seems physiologically incapable of laughter try to tell a couple of jokes,
  <a href="https://www.ted.com/talks/sam_harris_can_we_build_ai_without_losing_control_over_it" rel="noopener" target="_blank">
   <span style="color:#993300;">
    you can watch this TED talk
   </span>
  </a>
  .  If you got here from SlateStarCodex and only want to read stuff by Scott, you
  <a href="http://slatestarcodex.com/tag/ai/" rel="noopener" target="_blank">
   <span style="color:#993300;">
    can read any
   </span>
  </a>
  of the
  <a href="http://slatestarcodex.com/tag/transhumanism/" rel="noopener" target="_blank">
   <span style="color:#993300;">
    dozens of posts
   </span>
  </a>
  by Scott.
 </p>
 <hr/>
 <p>
  I do hope you take the time to follow the above links, so I’ll limit the discussion here to the only thing I know in life: opinion distribution curves.
 </p>
 <p>
  An important characteristic of the climate change opinion distribution curve is that the smarter opinions are closer to the middle than to the extremes. It’s not there aren’t stupid people holding opinions close to the median for stupid reasons, it’s that there isn’t a lot of intelligent discussion around the tails.
 </p>
 <p>
  In contrast, the opinion distribution curve on AI looks like this:
 </p>
 <p>
  <img alt="AI opinion curve" class="alignnone size-full wp-image-28449" data-attachment-id="28449" data-comments-opened="1" data-image-description="" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="AI opinion curve" data-large-file="https://putanumonit.files.wordpress.com/2017/12/ai-opinion-curve.png?w=900" data-medium-file="https://putanumonit.files.wordpress.com/2017/12/ai-opinion-curve.png?w=300" data-orig-file="https://putanumonit.files.wordpress.com/2017/12/ai-opinion-curve.png" data-orig-size="1057,561" data-permalink="https://putanumonit.com/2017/12/10/worried-about-ai/ai-opinion-curve/" sizes="(max-width: 900px) 100vw, 900px" src="https://putanumonit.files.wordpress.com/2017/12/ai-opinion-curve.png?w=900" srcset="https://putanumonit.files.wordpress.com/2017/12/ai-opinion-curve.png?w=900 900w, https://putanumonit.files.wordpress.com/2017/12/ai-opinion-curve.png?w=150 150w, https://putanumonit.files.wordpress.com/2017/12/ai-opinion-curve.png?w=300 300w, https://putanumonit.files.wordpress.com/2017/12/ai-opinion-curve.png?w=768 768w, https://putanumonit.files.wordpress.com/2017/12/ai-opinion-curve.png?w=1024 1024w, https://putanumonit.files.wordpress.com/2017/12/ai-opinion-curve.png 1057w"/>
 </p>
 <p>
  As a
  <del datetime="2017-12-10T12:29:04-05:00">
   society
  </del>
  species, the sensible direction for our collective curve to move is to be a hell of a lot more worried about AI.
 </p>
 <p>
  Fortunately, this seems to be happening. There’s a solid trend of smart people like Elon Musk, Bill Gates, Stephen Hawking,
  <a href="http://slatestarcodex.com/2015/05/22/ai-researchers-on-ai-risk/" rel="noopener" target="_blank">
   and a long list of computer scientists from Alan Turing to Stuart Russell
  </a>
  who have become a lot more worried about superintelligent AI immediately after giving the subject serious thought. It’s time to join them.
 </p>
 <hr/>
 <p>
  A smart thing to do if we’re worried about AI is to donate money to AI alignment research
  <em>
   right now
  </em>
  . We don’t know how far away superintelligent AI is, and we will probably
  <a href="https://intelligence.org/2017/10/13/fire-alarm/" rel="noopener" target="_blank">
   think that it’s decades away until the last year or two
  </a>
  ; by then it will be quite late. Also, scientific research is something that builds on itself over time. A problem that takes 50 years for scientists to solve can’t usually be solved in 5 years with a tenfold budget.
 </p>
 <p>
  There’s a good reason for Americans, in particular, to donate money before the end of 2017. The
  <a href="https://www.cnbc.com/2017/11/03/the-good-the-bad-and-the-money-what-the-gop-tax-plan-means-for-you.html" rel="noopener" target="_blank">
   new tax plan
  </a>
  raises the standard deduction to $12k/$24k and eliminates most itemized deductions. This means that you won’t get to deduct the first several thousand dollars of charity donations going forward, but you can in 2017. Whatever amount you were going to donate in 2018, it makes sense to donate it now and get a tax cut.
 </p>
 <p>
  A non-suicidal civilization should be dealing with existential risk collectively, for example with a government-funded “AI safety Manhattan project” of our best scientists. We’re not there yet, and in the meantime, private donations by smart people need to carry the load. To get
  <em>
   there
  </em>
  it’s also important to spread the word, which is why I’m blogging about matching funds publicly instead of giving anonymously.
 </p>
 <p>
  I am planning to donate to the
  <a href="https://intelligence.org/2017/12/01/miris-2017-fundraiser/" rel="noopener" target="_blank">
   Machine Intelligence Research Institute fundraiser
  </a>
  because I’m reasonably certain that MIRI is doing important work on AI alignment. However, I’m not as certain that they’re the absolute best in the field. I encourage my readers to look at other organizations like the
  <a href="https://futureoflife.org/" rel="noopener" target="_blank">
   Future of Life Institute
  </a>
  , the
  <a href="http://humancompatible.ai/" rel="noopener" target="_blank">
   Center for Human-Compatible AI
  </a>
  , the
  <a href="http://existence.org/" rel="noopener" target="_blank">
   Berkeley Existential Risk Initiative
  </a>
  , the
  <a href="https://www.fhi.ox.ac.uk/" rel="noopener" target="_blank">
   Future of Humanity Institute
  </a>
  at Oxford, and the
  <a href="https://app.effectivealtruism.org/funds/far-future" rel="noopener" target="_blank">
   Effective Altruism Far Future Fund
  </a>
  . In my donation to MIRI, I will
  <strong>
   match the amount
  </strong>
  donated by my readers to any legitimate organization that deals with existential risk, up to 0.3 Bitcoins (currently
  <span style="color:#0000ff;">
   $5,150
  </span>
  ).
 </p>
 <p>
  I will go ahead with my donation on December 24th, so in the next two weeks please consider giving some money to ensure that humanity survives beyond our generation.
  <a href="mailto:putanumonit@gmail.com" rel="noopener" target="_blank">
   Email me your donation receipt
  </a>
  when you do, and I will happily give you credit on this blog. I will include or exclude according to your wishes any of the following information: your name, the amount donated, the organization you chose, and the reason for your donation.
 </p>
 <p>
  Good Solstice, Merry Christmas, Hag Hannukah Sameah, Joyous Kwanzaa, and Happy Far Future to us all!
 </p>
 <hr/>
 <p>
  Donation update – my readers have donated over $35,000 and I matched over $5,000 of my own to MIRI!
 </p>
 <p>
  Below are the names, amounts, and explanations from all the donors who wanted those details made public, some of us also made
  <a href="https://intelligence.org/topcontributors/" rel="noopener" target="_blank">
   MIRI’s list of top contributors
  </a>
  .
 </p>
 <p>
  <span style="color:#993366;">
   <strong>
    James Landis
   </strong>
  </span>
  – 1 BTC.
  <em>
   “Now is a really good time to donate Bitcoin to charity – it harnesses the greed of speculation and counterbalances all the unethical uses of the currency so far (
  </em>
  cryptolocker
  <em>
   being among the worst). It’s a great way to capture all of the capital gains without any of the tax penalty, too!”
  </em>
 </p>
 <p>
  <span style="color:#993366;">
   <strong>
    Clark Gaebel
   </strong>
  </span>
  – $12,000.
  <em>
   “For a long time now (well before hearing about the AI-risk folk), I’ve considered unfriendly AI to be inevitable without intervention. As a fun exercise, spend 30 quiet seconds thinking of a way to design a super-intelligence which makes as many paperclips as
  </em>
  possible,
  <em>
   and isn’t dangerous. It’s hard!
  </em>
 </p>
 <p>
  <em>
   Designing a general optimizer is hard. Once upon a time, I thought deep learning wasn’t good enough to get there. Complicated, deep, neural networks pattern-matched in my head to “overfitting”. But when AlphaZero pwned stockfish, I updated. It didn’t just beat humans at chess. It beat the best humans
   <u>
    with the assistance of a computer
   </u>
   at chess”
  </em>
 </p>
 <p>
  <span style="color:#993366;">
   <strong>
    Kevin Fischer
   </strong>
  </span>
  – $5000.
  <em>
   “I’ve never donated to MIRI or any other non-profit in the AI alignment field before, but your article convinced me to do so this year.”
  </em>
 </p>
 <p>
  I have also received donation receipts from
  <span style="color:#993366;">
   <strong>
    Triinu
   </strong>
  </span>
  ,
  <span style="color:#993366;">
   <strong>
    Cliff
   </strong>
  </span>
  ,
  <span style="color:#993366;">
   <strong>
    Matthijs
   </strong>
  </span>
  ,
  <span style="color:#993366;">
   <strong>
    Keegan
   </strong>
  </span>
  . and
  <span style="color:#993366;">
   <strong>
    Eric
   </strong>
  </span>
  . If any of the above want your details published, let me know.
 </p>
 <p>
  If I forgot someone who donated let me know ASAP, and if you were partly inspired by my blog to donate you can email me your donation receipt and I’ll add you to the list as well.
 </p>
 <p>
  <img alt="MIRI donation" class="alignnone size-full wp-image-28470" data-attachment-id="28470" data-comments-opened="1" data-image-description="" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="MIRI donation" data-large-file="https://putanumonit.files.wordpress.com/2017/12/miri-donation.png?w=733" data-medium-file="https://putanumonit.files.wordpress.com/2017/12/miri-donation.png?w=300" data-orig-file="https://putanumonit.files.wordpress.com/2017/12/miri-donation.png" data-orig-size="733,396" data-permalink="https://putanumonit.com/2017/12/10/worried-about-ai/miri-donation/" sizes="(max-width: 733px) 100vw, 733px" src="https://putanumonit.files.wordpress.com/2017/12/miri-donation.png?w=900" srcset="https://putanumonit.files.wordpress.com/2017/12/miri-donation.png 733w, https://putanumonit.files.wordpress.com/2017/12/miri-donation.png?w=150 150w, https://putanumonit.files.wordpress.com/2017/12/miri-donation.png?w=300 300w"/>
 </p>
 <p>
  Thank you all!
 </p>
 <div class="sharedaddy sd-like-enabled sd-sharing-enabled" id="jp-post-flair">
  <div class="sharedaddy sd-sharing-enabled">
   <div class="robots-nocontent sd-block sd-social sd-social-icon sd-sharing">
    <h3 class="sd-title">
     Share this:
    </h3>
    <div class="sd-content">
     <ul>
      <li class="share-facebook">
       <a class="share-facebook sd-button share-icon no-text" data-shared="sharing-facebook-28447" href="https://putanumonit.com/2017/12/10/worried-about-ai/?share=facebook" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on Facebook">
        <span>
        </span>
        <span class="sharing-screen-reader-text">
         Click to share on Facebook (Opens in new window)
        </span>
       </a>
      </li>
      <li class="share-twitter">
       <a class="share-twitter sd-button share-icon no-text" data-shared="sharing-twitter-28447" href="https://putanumonit.com/2017/12/10/worried-about-ai/?share=twitter" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on Twitter">
        <span>
        </span>
        <span class="sharing-screen-reader-text">
         Click to share on Twitter (Opens in new window)
        </span>
       </a>
      </li>
      <li class="share-pocket">
       <a class="share-pocket sd-button share-icon no-text" data-shared="" href="https://putanumonit.com/2017/12/10/worried-about-ai/?share=pocket" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on Pocket">
        <span>
        </span>
        <span class="sharing-screen-reader-text">
         Click to share on Pocket (Opens in new window)
        </span>
       </a>
      </li>
      <li class="share-reddit">
       <a class="share-reddit sd-button share-icon no-text" data-shared="" href="https://putanumonit.com/2017/12/10/worried-about-ai/?share=reddit" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on Reddit">
        <span>
        </span>
        <span class="sharing-screen-reader-text">
         Click to share on Reddit (Opens in new window)
        </span>
       </a>
      </li>
      <li class="share-tumblr">
       <a class="share-tumblr sd-button share-icon no-text" data-shared="" href="https://putanumonit.com/2017/12/10/worried-about-ai/?share=tumblr" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on Tumblr">
        <span>
        </span>
        <span class="sharing-screen-reader-text">
         Click to share on Tumblr (Opens in new window)
        </span>
       </a>
      </li>
      <li class="share-email">
       <a class="share-email sd-button share-icon no-text" data-shared="" href="https://putanumonit.com/2017/12/10/worried-about-ai/?share=email" rel="nofollow noopener noreferrer" target="_blank" title="Click to email this to a friend">
        <span>
        </span>
        <span class="sharing-screen-reader-text">
         Click to email this to a friend (Opens in new window)
        </span>
       </a>
      </li>
      <li class="share-end">
      </li>
     </ul>
    </div>
   </div>
  </div>
  <div class="sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-unloaded" data-name="like-post-frame-101823629-28447-6010a75bb88a4" data-src="//widgets.wp.com/likes/index.html?ver=20200826#blog_id=101823629&amp;post_id=28447&amp;origin=putanumonit.wordpress.com&amp;obj_id=101823629-28447-6010a75bb88a4&amp;domain=putanumonit.com" id="like-post-wrapper-101823629-28447-6010a75bb88a4">
   <h3 class="sd-title">
    Like this:
   </h3>
   <div class="likes-widget-placeholder post-likes-widget-placeholder" style="height: 55px;">
    <span class="button">
     <span>
      Like
     </span>
    </span>
    <span class="loading">
     Loading...
    </span>
   </div>
   <span class="sd-text-color">
   </span>
   <a class="sd-link-color">
   </a>
  </div>
  <div class="jp-relatedposts" id="jp-relatedposts">
   <h3 class="jp-relatedposts-headline">
    <em>
     Related
    </em>
   </h3>
  </div>
 </div>
</div>