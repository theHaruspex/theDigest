<h1>
<meta charset="utf-8">
 The Secret Society for Suppressing Stupidity
</h1>
<h2>
</h2>
<i>
 Published May 17, 2016 on Put A Number On It!.
</i>
<div class="entry-content">
 <h2>
  The People of the Book
 </h2>
 <p>
  A long long time ago (by internet standards), in a faraway land (I dunno, probably California), a bearded man from a Jewish family sat down to write a
  <span style="color:#ff6600;">
   <a href="https://wiki.lesswrong.com/wiki/Sequences#Rationality:_From_AI_to_Zombies" style="color:#ff6600;" target="_blank">
    book
   </a>
  </span>
  . And in that book he set out to teach people how to think well, so that humanity may at last achieve
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/h8/tsuyoku_naritai_i_want_to_become_stronger/" style="color:#ff6600;" target="_blank">
    wisdom
   </a>
  </span>
  and
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/ww/high_challenge/" style="color:#ff6600;" target="_blank">
    salvation
   </a>
  </span>
  . This is apparently something that bearded men from Jewish families are prone to try every few centuries or so. And the art of thinking well he wrote about was known as
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/31/what_do_we_mean_by_rationality/" style="color:#ff6600;" target="_blank">
    Rationality
   </a>
  </span>
  .
 </p>
 <p>
  And around that book, which was then known as
  <em>
   “The Rationality Sequences”
  </em>
  , gathered wise women and men who
  <del>
   accepted everything unquestioningly
  </del>
  nitpicked every single
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/mt/beautiful_probability/#comments" style="color:#ff6600;" target="_blank">
    sentence and equation
   </a>
  </span>
  and even the
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/9p/extreme_rationality_its_not_that_great/" style="color:#ff6600;" target="_blank">
    entire goal of the book
   </a>
  </span>
  . And yet basically everyone who read The Sequences agreed that they are an excellent guide to reasoning well, that everything in them is so simple and true that
  <span style="color:#ff6600;">
   <a href="http://slatestarcodex.com/2014/03/13/five-years-and-one-week-of-less-wrong/" style="color:#ff6600;" target="_blank">
    it all seems completely obvious in hindsight
   </a>
  </span>
  . Of course, this is exactly what the
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/im/hindsight_devalues_science/" style="color:#ff6600;" target="_blank">
    book warned them will happen
   </a>
  </span>
  . And this group of people who read The Sequences came to be known as the
  <span style="color:#008000;">
   <a href="http://slatestarcodex.com/blog_images/ramap.html" style="color:#008000;" target="_blank">
    Rationalist Community
   </a>
  </span>
  . Although, being proper rationalists, the group
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/zx/my_concerns_about_the_term_rationalist/" style="color:#ff6600;" target="_blank">
    kept arguing for years
   </a>
  </span>
  over whether that
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/82s/dont_call_yourself_a_rationalist/" style="color:#ff6600;" target="_blank">
    was a good name or not
   </a>
  </span>
  .
 </p>
 <p>
  And lo, other people saw them reading The Sequences and having a good time. And the others spake thus to the rationalists:
  <em>
   “LOL, you’re a bunch of nerds in a dumbass cult.”
  </em>
  And the rationalists patiently explained that no, the entire art was about thinking
  <em>
   independently
  </em>
  . And that as he was writing The Sequences, Eliezer anticipated that they will be so fun to read that people will forget to be skeptical, and dedicated an
  <span style="color:#ff6600;">
   <a href="https://wiki.lesswrong.com/wiki/Death_Spirals_and_the_Cult_Attractor" style="color:#ff6600;" target="_blank">
    entire huge section of the book to avoiding groupthink and cultiness
   </a>
  </span>
  . And that even though every two rationalists agree on 95% of the book’s conclusions, they
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/q8/many_worlds_one_best_guess/#comments" style="color:#ff6600;" target="_blank">
    spend all their time
   </a>
  </span>
  arguing over
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/kn/torture_vs_dust_specks/#comments" style="color:#ff6600;" target="_blank">
    the 5% they disagree on
   </a>
  </span>
  , lest anyone accuse them of not being skeptical enough.
 </p>
 <p>
  On the other hand, the rationalists confirmed that yes, they were a bunch of nerds.
 </p>
 <p>
  <img alt="eliezer MW.png" class="size-full wp-image-10208 aligncenter" data-attachment-id="10208" data-comments-opened="1" data-image-description="" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="eliezer MW" data-large-file="https://putanumonit.files.wordpress.com/2016/05/eliezer-mw.png?w=496" data-medium-file="https://putanumonit.files.wordpress.com/2016/05/eliezer-mw.png?w=300" data-orig-file="https://putanumonit.files.wordpress.com/2016/05/eliezer-mw.png" data-orig-size="496,430" data-permalink="https://putanumonit.com/2016/05/17/rationality/eliezer-mw/" sizes="(max-width: 496px) 100vw, 496px" src="https://putanumonit.files.wordpress.com/2016/05/eliezer-mw.png?w=900" srcset="https://putanumonit.files.wordpress.com/2016/05/eliezer-mw.png 496w, https://putanumonit.files.wordpress.com/2016/05/eliezer-mw.png?w=150 150w, https://putanumonit.files.wordpress.com/2016/05/eliezer-mw.png?w=300 300w"/>
 </p>
 <p>
  And the others didn’t relent and spake thus to the rationalists:
  <em>
   “So what are you nerds doing with your fancy rationality other than squabbling about it on an internet forum?”
  </em>
  And the rationalists didn’t answer because they and their friends were too busy
  <span style="color:#008000;">
   <a href="https://www.centreforeffectivealtruism.org/" style="color:#008000;" target="_blank">
    helping the needy
   </a>
  </span>
  , and
  <span style="color:#008000;">
   <a href="http://rationality.org/" style="color:#008000;" target="_blank">
    spreading the art
   </a>
  </span>
  , and
  <span style="color:#008000;">
   <a href="https://www.beeminder.com/" style="color:#008000;" target="_blank">
    launching
   </a>
  </span>
  a
  <a href="https://www.quixey.com/company/" target="_blank">
   <span style="color:#008000;">
    bunch
   </span>
  </a>
  of
  <span style="color:#008000;">
   <a href="http://www.mealsquares.com" style="color:#008000;" target="_blank">
    start-ups
   </a>
  </span>
  , and
  <span style="color:#008000;">
   <a href="http://www.gwern.net/" style="color:#008000;" target="_blank">
    advancing science
   </a>
  </span>
  , and
  <span style="color:#008000;">
   <a href="http://futureoflife.org/" style="color:#008000;" target="_blank">
    saving humanity
   </a>
  </span>
  from
  <span style="color:#008000;">
   <a href="https://intelligence.org/" style="color:#008000;" target="_blank">
    extinction
   </a>
  </span>
  .
 </p>
 <p>
  And yet the others persisted and spake thus to the rationalists:
  <em>
   “OMG you guys, that book is like so 2007. Get with the program, the hip place to be now is
   <strong>
    post
   </strong>
   -rationality.”
  </em>
  And the rationalists asked what errors there were in the book that it should be discarded in favor of something new?
  <strong>
   But the answer is that there isn’t anything wrong with The Sequences, and they successfully anticipated 9 years ago basically every challenge thrown at them since, and
   <span style="color:#ff6600;">
    <a href="https://intelligence.org/rationality-ai-zombies/" style="color:#ff6600;" target="_blank">
     all of you should go and read them right now
    </a>
   </span>
   .
  </strong>
  But these very smug “postrationalists” did contribute to an annoying aura of unfashionability that formed around LessWrong and keeps new people from benefitting from it.
 </p>
 <p>
  This is a good place to stop reading this post and start reading
  <span style="color:#ff6600;">
   <a href="https://wiki.lesswrong.com/wiki/Sequences" style="color:#ff6600;" target="_blank">
    The Sequences
   </a>
  </span>
  – they’re pretty long (
  <em>
   vita brevis
  </em>
  <em>
   ars longa
  </em>
  and all that) and are also better written. In case you haven’t noticed yet, all the links in orange are to LessWrong and the rationality sequences, to give you a taste of the massive breadth of ideas they cover. If you don’t like clicking on links for some reason, I’ll give a short overview of how I see rationality and vent a bit about “postrationalists”.
 </p>
 <hr/>
 <h2>
  From Huitzilopochtli to Rationality
 </h2>
 <p>
  Humanity went from thinking that the sun was a
  <span style="color:#008000;">
   <a href="http://content.time.com/time/specials/packages/article/0,28804,2046823_2046865_2046845,00.html" style="color:#008000;" target="_blank">
    hummingbird-shaped warrior god requiring human sacrifice
   </a>
  </span>
  to using solar radiation pressure to power
  <span style="color:#008000;">
   <a href="https://en.wikipedia.org/wiki/IKAROS" style="color:#008000;" target="_blank">
    interplanetary spacecraft
   </a>
  </span>
  . We credit most impressive achievements like that to science, and some to Al Gore. Science started working when it noticed a couple of things:
 </p>
 <ol>
  <li>
   The hummingbird god sounds super cool, but
   <em>
    coolness
   </em>
   is a bad indicator of whether something is true. Instead, we can find out what is true by
   <strong>
    looking at it
   </strong>
   . Early scientists believed that “looking at it” meant “looking at the sun directly”, that didn’t work out well. Later scientists expanded that idea a bit to mean
   <strong>
    learning about reality from observing evidence
   </strong>
   .
  </li>
  <li>
   The best way to organize and express scientifically what we know about reality seems to be by putting numbers on it. Reality is very complex and our information is very limited, so we need to use numbers that represent
   <strong>
    incomplete knowledge
   </strong>
   <em>
    .
   </em>
   The use of numbers to talk about incomplete knowledge is described by
   <strong>
    probability theory
   </strong>
   .
  </li>
 </ol>
 <p>
  It also turns out that if you ask
  <strong>
   probability
  </strong>
  <strong>
   theory
  </strong>
  how you should
  <strong>
   learn about reality
  </strong>
  from
  <strong>
   observing evidence
  </strong>
  , it will tell you that while the actual implementation may differ wildly from case to case, at the core of it you should be doing something that looks like
  <span style="color:#008000;">
   <a href="https://arbital.com/p/bayes_rule_guide/" style="color:#008000;" target="_blank">
    Bayes’ theorem
   </a>
  </span>
  . Since in popular culture the label “rational” is usually applied to
  <span style="color:#008000;">
   <a href="http://tvtropes.org/pmwiki/pmwiki.php/Main/StrawVulcan" style="color:#008000;" target="_blank">
    utterly irrational strawman characters
   </a>
  </span>
  , the term “Bayesian” is sometimes used in the rationality community instead.
 </p>
 <p>
  Hey, look! Someone wrote a great book called
  <span style="color:#008000;">
   <a href="http://bayes.wustl.edu/etj/prob/book.pdf" style="color:#008000;" target="_blank">
    <em>
     Probability Theory: The Logic of Science
    </em>
   </a>
  </span>
  .
 </p>
 <p>
  <img alt="jaynes.png" class="size-full wp-image-10197 aligncenter" data-attachment-id="10197" data-comments-opened="1" data-image-description="" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="jaynes" data-large-file="https://putanumonit.files.wordpress.com/2016/05/jaynes.png?w=182" data-medium-file="https://putanumonit.files.wordpress.com/2016/05/jaynes.png?w=182" data-orig-file="https://putanumonit.files.wordpress.com/2016/05/jaynes.png" data-orig-size="182,277" data-permalink="https://putanumonit.com/2016/05/17/rationality/jaynes/" sizes="(max-width: 182px) 100vw, 182px" src="https://putanumonit.files.wordpress.com/2016/05/jaynes.png?w=900" srcset="https://putanumonit.files.wordpress.com/2016/05/jaynes.png 182w, https://putanumonit.files.wordpress.com/2016/05/jaynes.png?w=99 99w"/>
 </p>
 <p>
  “Figuring out what reality is like” is something that scientists get paid for, but non-scientists occasionally find uncovering the truth useful as well. Perhaps you want to know how long a
  <span style="color:#008000;">
   <a href="https://en.wikipedia.org/wiki/Planning_fallacy#For_individual_tasks" style="color:#008000;" target="_blank">
    project will take you to finish
   </a>
  </span>
  , how
  <a href="http://vegasclick.com/gambling/fallacy.html" target="_blank">
   <span style="color:#008000;">
    likely a roulette wheel is to come up
   </span>
   <span style="color:#008000;">
    red
   </span>
  </a>
  , whether you
  <span style="color:#008000;">
   <a href="http://michaelgr.com/2007/11/24/cognitive-bias-base-rate-fallacy/" style="color:#008000;" target="_blank">
    have breast cancer or not
   </a>
  </span>
  . That seems simple enough, but all the links you didn’t click on in the previous sentence demonstrate that humans systematically suck at answering these simple questions, and
  <span style="color:#008000;">
   <a href="https://en.wikipedia.org/wiki/Heuristics_in_judgment_and_decision-making" style="color:#008000;" target="_blank">
    many many many more
   </a>
  </span>
  .
 </p>
 <p>
  Why is it hard for our brains to simply reject things that are false and believe things that are true? It unfortunately turns out that instead of pristine engines of perfect reasoning inside our heads we are stuck will kludgy, squishy, meat-computer monkey brains. And monkey brains will believe an idea for many reasons:
 </p>
 <ul>
  <li>
   The idea seems nice and pleasant to believe in.
  </li>
  <li>
   It is politically expedient to believe in the idea.
  </li>
  <li>
   The idea props up our self esteem.
  </li>
  <li>
   People around us say the idea out loud and repeat it.
  </li>
  <li>
   The idea is something we try to convince others of, and we lie better when we believe in the lie ourselves.
  </li>
  <li>
   The idea fits in with other wrong ideas we lug around in our brains.
  </li>
  <li>
   An authoritative-looking person told us it’s true and we never bothered to check.
  </li>
  <li>
   On very rare occasion, we believe an idea because we have seen evidence that shows it to be true.
  </li>
 </ul>
 <p>
  You may have heard of another great book, this one’s about the ways our brains are predictably wrong about stuff all the time, it’s called
  <span style="color:#008000;">
   <a href="https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow" style="color:#008000;" target="_blank">
    Thinking Fast and Slow
   </a>
  </span>
  .
 </p>
 <p>
  <a href="http://www.google.com/url?sa=i&amp;rct=j&amp;q=&amp;esrc=s&amp;source=images&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiDgcCs7tfMAhXGcj4KHWT5Ab4QjRwIBw&amp;url=http%3A%2F%2Fwww.summary.com%2Fbook-reviews%2F_%2FThinking-Fast-and-Slow%2F&amp;psig=AFQjCNEb4hKHVr6muE0z47NrdivHhO2AoQ&amp;ust=1463256689177624" id="irc_mil">
   <img alt="" class="aligncenter" height="200" id="irc_mi" src="https://i1.wp.com/cdn04.summary.com/_resources/_global/media/resized/00017/ihwx.9859ea52-1ff1-4c34-8216-5c0327aa2f47.200.175.jpg" width="175"/>
  </a>
 </p>
 <p>
  The bad news is that trying to teach your kludgy monkey brain to overcome the fact that it’s a kludgy monkey brain is confusing, difficult and unpleasant.
  <span style="color:#008000;">
   <a href="http://www.newyorker.com/tech/frontal-cortex/why-smart-people-are-stupid" style="color:#008000;" target="_blank">
    Intelligence, expertise and general awareness of biases
   </a>
  </span>
  don’t help much in this pursuit, and
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/he/knowing_about_biases_can_hurt_people/" style="color:#ff6600;" target="_blank">
    may even actively derail you
   </a>
  </span>
  . Not only is becoming fully rational quite impossible, even starting to make progress is a challenge: it requires overcoming the
  <span style="color:#008000;">
   <a href="http://www.cmu.edu/news/stories/archives/2015/june/bias-blind-spot.html" style="color:#008000;" target="_blank">
    huge bias blindspot
   </a>
  </span>
  that prevents you from even accepting that you may be irrational on occasion. Your brain will continue to insist to you that it’s perfectly reasonable, even as it’s holding wrong, harmful and even contradictory beliefs.
 </p>
 <p>
  The good news is that
  <span style="color:#008000;">
   <a href="http://lesswrong.com/lw/lhg/2014_survey_results/" style="color:#008000;" target="_blank">
    you aren’t alone
   </a>
  </span>
  : there are rationalists in the Bronx and in Bermuda, transgender mathematician rationalists and religious lawyer rationalists, polyamorous communists and conservative asexual rationalists. There are
  <span style="color:#008000;">
   <a href="http://lesswrong.com/meetups/" style="color:#008000;" target="_blank">
    meetups
   </a>
  </span>
  on 5 continents and in three different cities in the Bay Area. Most importantly,
  <span style="color:#008000;">
   <a href="http://slatestarcodex.com/2014/03/13/five-years-and-one-week-of-less-wrong/" style="color:#008000;" target="_blank">
    The Sequences gave the community a common language
   </a>
  </span>
  to talk about rationality. Like the
  <span style="color:#008000;">
   <a href="http://www.slate.com/blogs/lexicon_valley/2013/10/16/piraha_cognitive_anumeracy_in_a_language_without_numbers.html" style="color:#008000;" target="_blank">
    tribe who can’t tell quantities apart
   </a>
  </span>
  because they have no words for counting numbers, learning rationality would be almost impossible without the vocabulary.
 </p>
 <p>
  I don’t know how I could explain why donating to
  <span style="color:#008000;">
   <a href="https://putanumonit.com/2016/04/27/more-power-less-poverty/" style="color:#008000;" target="_blank">
    basic income charity
   </a>
  </span>
  shouldn’t be compared in the framework of
  <span style="color:#008000;">
   <a href="https://putanumonit.com/2016/05/11/shopping-for-happiness/" style="color:#008000;" target="_blank">
    buying happiness
   </a>
  </span>
  if I hadn’t heard of
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/6z/purchase_fuzzies_and_utilons_separately/" style="color:#ff6600;" target="_blank">
    fuzzies and utilons
   </a>
  </span>
  . In fact, I probably wouldn’t have even understood it myself. On the other hand, I spent extra time looking for possible negative consequences of basic income because I felt that I was in danger of falling into a
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/ln/resist_the_happy_death_spiral/" style="color:#ff6600;" target="_blank">
    happy death spiral
   </a>
  </span>
  around a cool idea. I found myself supporting basic income
  <strong>
   more
  </strong>
  after reading arguments that BIG reduces employment, because all these arguments are stupid. I had to remind myself that
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/lw/reversed_stupidity_is_not_intelligence/" style="color:#ff6600;" target="_blank">
    reversed stupidity isn’t intelligence
   </a>
  </span>
  : a
  <em>
   bad
  </em>
  argument against BIG doesn’t
  <em>
   make
  </em>
  BIG a better policy. I read a sophisticated argument with many steps explaining how BIG will
  <em>
   reduce
  </em>
  taxes in the US if it was implemented, and dismissed it as well. It seemed like a clear case of writing the
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/js/the_bottom_line/" style="color:#ff6600;" target="_blank">
    bottom line
   </a>
  </span>
  first to support an
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/gz/policy_debates_should_not_appear_onesided/" style="color:#ff6600;" target="_blank">
    apparent one-sided policy
   </a>
  </span>
  , and the multitude of necessary steps was clearly vulnerable to the
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/ji/conjunction_fallacy/" style="color:#ff6600;" target="_blank">
    conjunction fallacy
   </a>
  </span>
  .
 </p>
 <p>
  I don’t even remember how it was possible to think about complicated things like economic policy without rationality training. I probably
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/gw/politics_is_the_mindkiller/" style="color:#ff6600;" target="_blank">
    wasn’t thinking much at all
   </a>
  </span>
  , just falling in step with the correct
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/gt/a_fable_of_science_and_politics/" style="color:#ff6600;" target="_blank">
    blue/green position
   </a>
  </span>
  . If you asked me now whether I think BIG will increase the quality of life for Americans compared to the current welfare system I would say
  <em>
   “75% yes, subject to appropriate updates after the research results are in”
  </em>
  . Can you imagine a policy maker giving an answer like that? And yet any answer on such a complex topic that’s not
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/mp/0_and_1_are_not_probabilities/" style="color:#ff6600;" target="_blank">
    in the form of a probability between 0 and 1
   </a>
  </span>
  strikes me now as utter insanity. Browsing through my Facebook history, I’m embarrassed by 90% of the “political” views I held before discovering rationality. Not because they’re all wrong, but because I held and proclaimed them for embarrassing reasons.
 </p>
 <p>
  <img alt="blue green" class="wp-image-10433 aligncenter" data-attachment-id="10433" data-comments-opened="1" data-image-description="" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="blue green" data-large-file="https://putanumonit.files.wordpress.com/2016/05/blue-green.png?w=760" data-medium-file="https://putanumonit.files.wordpress.com/2016/05/blue-green.png?w=300" data-orig-file="https://putanumonit.files.wordpress.com/2016/05/blue-green.png" data-orig-size="760,573" data-permalink="https://putanumonit.com/2016/05/17/rationality/blue-green/" height="302" loading="lazy" sizes="(max-width: 401px) 100vw, 401px" src="https://putanumonit.files.wordpress.com/2016/05/blue-green.png?w=401&amp;h=302" srcset="https://putanumonit.files.wordpress.com/2016/05/blue-green.png?w=401&amp;h=302 401w, https://putanumonit.files.wordpress.com/2016/05/blue-green.png?w=150&amp;h=113 150w, https://putanumonit.files.wordpress.com/2016/05/blue-green.png?w=300&amp;h=226 300w, https://putanumonit.files.wordpress.com/2016/05/blue-green.png 760w" width="401"/>
 </p>
 <p>
  I hope that all the examples I have given so far seem like simple common sense. Why do we need to go to all this trouble of learning about Bayesian probability and decision heuristics and the rest?
  <span style="color:#008000;">
   <a href="http://slatestarcodex.com/2013/08/06/on-first-looking-into-chapmans-pop-bayesianism/" style="color:#008000;" target="_blank">
    I’ll let Scott explain
   </a>
  </span>
  :
 </p>
 <blockquote>
  <p>
   <span style="color:#333399;">
    I think Bayesianism is a genuine epistemology and that the only reason this isn’t obvious is that it’s a really
    <i>
     good
    </i>
    epistemology, so good that it’s hard to remember that other people don’t have it.
   </span>
  </p>
  <p>
   <span style="color:#333399;">
    …
   </span>
  </p>
  <p>
   <span style="color:#333399;">
    Probability theory in general, and Bayesianism in particular, provide a coherent philosophical foundation for not being an idiot.
   </span>
  </p>
  <p>
   <span style="color:#333399;">
    Now in general, people don’t need coherent philosophical foundations for anything they do. They don’t need grammar to speak a language, they don’t need classical physics to hit a baseball, and they don’t need probability theory to make good decisions. This is why I find all the “But probability theory isn’t that useful in everyday life!” complaining so vacuous.
   </span>
  </p>
  <p>
   <span style="color:#333399;">
    “Everyday life” means “inside your comfort zone”. You don’t need theory inside your comfort zone, because you already navigate it effortlessly. But sometimes you find that the inside of your comfort zone isn’t so comfortable after all (my go-to grammatical example is answering the phone “Scott? Yes, this is him.”) Other times you want to leave your comfort zone, by for example speaking a foreign language or creating a
    <a href="http://en.wikipedia.org/wiki/Conlang" style="color:#333399;">
     conlang
    </a>
    .
   </span>
  </p>
  <p>
   <span style="color:#333399;">
    When David says that [inferring the existence/nonexistence of God from evidence] doesn’t count because it’s an edge case, I respond that it’s
    <i>
     exactly
    </i>
    the sort of thing that should count because it’s people trying to actually
    <i>
     think
    </i>
    about an issue outside their comfort zone which they can’t handle on intuition alone. It turns out when most people try this they fail miserably. If you are the sort of person who likes to deal with complicated philosophical problems outside the comfortable area where you can rely on instinct – and politics, religion, philosophy, and charity all fall in that area – then it’s
    <i>
     really nice
    </i>
    to have an epistemology that doesn’t suck.
   </span>
  </p>
 </blockquote>
 <p>
  I’ll go even further than that: people make dumb, costly mistakes
  <em>
   inside
  </em>
  <em>
   their apparent comfort zone
  </em>
  <strong>
   all the time
  </strong>
  . I see people
  <span style="color:#ff6600;">
   <a href="https://wiki.lesswrong.com/wiki/Status_quo_bias" style="color:#ff6600;" target="_blank">
    stuck in jobs they hate
   </a>
  </span>
  because their brain is too lazy to snap out of a
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/hu/the_third_alternative/" style="color:#ff6600;" target="_blank">
    false dilemma
   </a>
  </span>
  . In these jobs they work on projects that fall to
  <span style="color:#ff6600;">
   <a href="https://wiki.lesswrong.com/wiki/Planning_fallacy" style="color:#ff6600;" target="_blank">
    planning fallacies
   </a>
  </span>
  and
  <span style="color:#ff6600;">
   <a href="https://wiki.lesswrong.com/wiki/Sunk_cost_fallacy" style="color:#ff6600;" target="_blank">
    sunk cost bias
   </a>
  </span>
  , if they manage at all to overcome
  <span style="color:#ff6600;">
   <a href="https://wiki.lesswrong.com/wiki/Akrasia" style="color:#ff6600;" target="_blank">
    procrastination and akrasia
   </a>
  </span>
  and do anything. They then spend the money they earned on purchases that
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/hl/lotteries_a_waste_of_hope/" style="color:#ff6600;" target="_blank">
    make them unhappy
   </a>
  </span>
  . They get into
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/od/37_ways_that_words_can_be_wrong/" style="color:#ff6600;" target="_blank">
    brainless arguments
   </a>
  </span>
  , fail to
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/kg/expecting_short_inferential_distances/" style="color:#ff6600;" target="_blank">
    explain or understand ideas
   </a>
  </span>
  , repeat
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/iq/guessing_the_teachers_password/" style="color:#ff6600;" target="_blank">
    empty words that mean nothing
   </a>
  </span>
  as if they were
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/k8/how_to_seem_and_be_deep/" style="color:#ff6600;" target="_blank">
    deep wisdom
   </a>
  </span>
  , and find
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/iu/mysterious_answers_to_mysterious_questions/" style="color:#ff6600;" target="_blank">
    solace in ignorance
   </a>
  </span>
  .
 </p>
 <p>
  If you’re cool with all of that then you probably shouldn’t waste your time with this book.
 </p>
 <p>
  <img alt="book equation.png" class="alignnone size-full wp-image-10477" data-attachment-id="10477" data-comments-opened="1" data-image-description="" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="book equation" data-large-file="https://putanumonit.files.wordpress.com/2016/05/book-equation.png?w=900" data-medium-file="https://putanumonit.files.wordpress.com/2016/05/book-equation.png?w=300" data-orig-file="https://putanumonit.files.wordpress.com/2016/05/book-equation.png" data-orig-size="1437,436" data-permalink="https://putanumonit.com/2016/05/17/rationality/book-equation/" sizes="(max-width: 900px) 100vw, 900px" src="https://putanumonit.files.wordpress.com/2016/05/book-equation.png?w=900" srcset="https://putanumonit.files.wordpress.com/2016/05/book-equation.png?w=900 900w, https://putanumonit.files.wordpress.com/2016/05/book-equation.png?w=150 150w, https://putanumonit.files.wordpress.com/2016/05/book-equation.png?w=300 300w, https://putanumonit.files.wordpress.com/2016/05/book-equation.png?w=768 768w, https://putanumonit.files.wordpress.com/2016/05/book-equation.png?w=1024 1024w, https://putanumonit.files.wordpress.com/2016/05/book-equation.png 1437w"/>
 </p>
 <hr/>
 <h2>
  Post-Rationality: Almost as Good as Rationality
 </h2>
 <p>
  Ok, so the on the plus side, Rationality is an epistemology and a community dedicated to thinking better and achieving goals strategically. On the minus side, it’s an aspiration and not a state that’s actually attainable. There’s a reason why the community hub is
  <em>
   lesswrong.com
  </em>
  (
  <span style="color:#008000;">
   <a href="http://lesswrong.com/lw/n0l/lesswrong_20/" style="color:#008000;" target="_blank">
    currently being rebooted to fit the evolving community
   </a>
  </span>
  ) and not
  <em>
   perfectwisdominfoureasysteps.com
  </em>
  (besides the fact that
  <span style="color:#008000;">
   <a href="https://putanumonit.com/2015/10/27/001-intro/" style="color:#008000;" target="_blank">
    shorter domain names are better
   </a>
  </span>
  ).
 </p>
 <p>
  It makes sense that some people will embrace Rationality and study it. It makes sense that most people will say
  <em>
   “Nah, I’m cool”
  </em>
  and stick with their old philosophies – that’s the human default behavior. What I’m confused by is people who are part of the broader rationality community who say
  <em>
   “Been there, done that. I figured out this rationality thing and moved on to something better now.”
  </em>
  Let’s see what they don’t like about Rationality.
 </p>
 <p>
  In a post called
  <span style="color:#008000;">
   <a href="https://yearlycider.wordpress.com/2014/09/19/postrationality-table-of-contents/" style="color:#008000;" target="_blank">
    Postrationality, a Table of Contents
   </a>
  </span>
  Yearly Cider writes:
 </p>
 <blockquote>
  <p>
   <span style="color:#333399;">
    Rationality tends to give advice like “ignore your intuitions/feelings, and rely on conscious reasoning and explicit calculation”. Postrationality, on the other hand, says “actually, intuitions and feelings are really important, let’s see if we can work with them instead of against them”.
   </span>
  </p>
  <p>
   <span style="color:#333399;">
    For instance, rationalists really like Kahneman’s System 1/System 2 model of the mind. In this model, System 1 is basically intuition, and System 2 is basically analytical reasoning. Furthermore, System 1 is fast, while System 2 is slow. I’ll describe this model in more detail in the next post, but basically, rationalists tend to see System 1 as a necessary evil: it’s inaccurate and biased, but it’s fast, and if you want to get all your reasoning done in time, you’ll just have to use the fast but crappy system. But for really important decisions, you should always use System 2. Actually, you should try to write out your probabilities explicitly and use those in your calculations; that is the best strategy for decision-making.
   </span>
  </p>
 </blockquote>
 <p>
  YC doesn’t cite specific examples of rationalists doing this, so we’ll look to the common base of Rationality, The Sequences, for an answer. Fortunately, The Sequences
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/go/why_truth_and/" style="color:#ff6600;" target="_blank">
    dispelled the above criticism seven years before it was written
   </a>
  </span>
  :
 </p>
 <blockquote>
  <p>
   <span style="color:#ff6600;">
    When people think of “emotion” and “rationality” as opposed, I suspect that they are really thinking of System 1 and System 2—fast perceptual judgments versus slow deliberative judgments. Deliberative judgments aren’t always true, and perceptual judgments aren’t always false; so it is very important to distinguish that dichotomy from “rationality”. Both systems can serve the goal of truth, or defeat it, according to how they are used.
   </span>
  </p>
 </blockquote>
 <p>
  RibbonFarm seems to have been labeled “postrationalist” based on
  <span style="color:#008000;">
   <a href="http://www.ribbonfarm.com/2015/11/05/ritual-epistemology/" style="color:#008000;" target="_blank">
    this guest post
   </a>
  </span>
  by Sarah Perry. The only criticism of Rationality in it seems to be that it rejects the value of ritual. For what it’s worth, there are both
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/us/the_ritual/" style="color:#ff6600;" target="_blank">
    made up rituals in The Sequences
   </a>
  </span>
  and
  <span style="color:#008000;">
   <a href="https://en.wikipedia.org/wiki/Secular_Solstice" style="color:#008000;" target="_blank">
    actual rituals for the community
   </a>
  </span>
  .
 </p>
 <p>
  <span style="color:#008000;">
   <a href="http://thefutureprimaeval.net/postrationalism/" style="color:#008000;" target="_blank">
    Warg Franklin seems to argue
   </a>
  </span>
  that Rationality is near enough to impossible as to be a waste of time, and that common sense and tradition are better guidelines:
 </p>
 <blockquote>
  <p>
   <span style="color:#333399;">
    Some rationalists have a reductionistic and mechanistic theory of mind. They see the mind made up of a patchwork of domain-specific biased heuristic algorithms which can be individually outsmarted and hacked for “debiasing”. While the mind is ultimately a reducible machine, it is complex, poorly understood, very clever, and designed to work as a purposeful whole. You generally can’t outsmart your mind. It is therefore better to treat the mind as a holistic and teleological black box system, and deal with it on its own terms; experience, intuitively understandable evidence, good ideas and arguments, and actual incentives. The mind is already well-tuned by evolution, and can only become wiser with lots of specific knowledge and experience, rather than more rational with a few high-impact cognitive hacks.
   </span>
  </p>
  <p>
   <span style="color:#333399;">
    We can’t really replace common sense and intuition as the basis of reasoning. Attempts to virtualize more “correct” principles of reasoning from math and cognitive science in explicit deliberative reasoning are unrealistic folly. We can learn useful metaphors from theory, and use mathematical tools, but theory cannot be the ultimate foundation of our cognition; practical reasoning is either based on reasonable common sense, or bogus.
   </span>
  </p>
 </blockquote>
 <p>
  There are good points here, but not nearly enough to condemn the pursuit of Rationality as useless. Yes, we know that Rationality is very hard, but
  <span style="color:#ff6600;">
   <a href="https://wiki.lesswrong.com/wiki/Challenging_the_Difficult" style="color:#ff6600;" target="_blank">
    there’s a guideline to doing impossible things
   </a>
  </span>
  as well. We know that the brain has been finely tuned by ages of evolution, but
  <span style="color:#ff6600;">
   <a href="https://wiki.lesswrong.com/wiki/Evolution#Blog_posts_.28sequence.29" style="color:#ff6600;" target="_blank">
    evolution is neither maximally-efficient nor aligned with the things we care about as humans
   </a>
  </span>
  .
 </p>
 <figure class="wp-caption aligncenter" style="width: 470px">
  <a href="http://www.google.com/url?sa=i&amp;rct=j&amp;q=&amp;esrc=s&amp;source=images&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjo5KTYxd_MAhVCHx4KHZkuDXYQjRwIBw&amp;url=http%3A%2F%2Fwww.latimes.com%2Fnation%2Fla-sh-cute-animals-2013-20131203-019-photo.html&amp;psig=AFQjCNF_mH6fy_GdiFLgQLnRLoY86dqtRw&amp;ust=1463520695229405" id="irc_mil">
   <img alt="" class="aligncenter" height="264" id="irc_mi" src="http://www.trbimg.com/img-529e20fe/turbine/la-sh-cute-animals-2013-20131203-019/1024/1024x576" width="470"/>
  </a>
  <figcaption class="wp-caption-text">
   This is your friendly reminder that evolution produced blobfish too
  </figcaption>
 </figure>
 <p>
  Finally, rationality aims to extend common sense and not contradict it, except in the face of some problems against which common sense and intuition are powerless. While writing The Sequences Eliezer was (and still is) trying to develop mathematical frameworks for a superintelligent AI that will also fulfill human values. That’s pretty hard, since human values are a
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/rm/the_design_space_of_mindsingeneral/" style="color:#ff6600;" target="_blank">
    miniscule region in the universe of possible goals
   </a>
  </span>
  an AI may pursue. As a species, we may only have one shot to solve this problem and without
  <em>
   extreme rationality
  </em>
  it’s completely intractable.
 </p>
 <p>
  Eliezer may not be sure that rationality is learnable by people who
  <span style="color:#ff6600;">
   <a href="http://lesswrong.com/lw/nb/something_to_protect/" style="color:#ff6600;" target="_blank">
    don’t dedicate their lives to a world-saving mission
   </a>
  </span>
  , but it doesn’t feel unattainable to me. I think that rationality in the service of making better
  <span style="color:#008000;">
   <a href="https://putanumonit.com/2016/05/11/shopping-for-happiness/" style="color:#008000;" target="_blank">
    soap buying decisions
   </a>
  </span>
  is still better than stupidity. With that said, I’ll probably
  <span style="color:#008000;">
   <a href="https://intelligence.org/donate/" style="color:#008000;" target="_blank">
    donate more money to MIRI
   </a>
  </span>
  this year than I’ll spend on soap, rationality does have a tendency to
  <span style="color:#008000;">
   <a href="http://lesswrong.com/lw/jl3/on_saving_the_world/" style="color:#008000;" target="_blank">
    light a world-saving spark
   </a>
  </span>
  in people.
 </p>
 <hr/>
 <h2>
  Bayesless Slander
 </h2>
 <p>
  Our tour of “postrationality” starts and ends with
  <span style="color:#008000;">
   <a href="http://meaningness.com/bayesian-eternalism" style="color:#008000;" target="_blank">
    David
   </a>
   <a href="http://meaningness.com/metablog/bayesianism-updating" style="color:#008000;" target="_blank">
    Chapman
   </a>
  </span>
  :
 </p>
 <blockquote>
  <p>
   <span style="color:#333399;">
    [1] In pop Bayesianism, the Rule is evidently
    <em>
     not
    </em>
    arithmetic; it is the sacred symbol of Rationality…Occasions in which you can actually apply the formula are rare. Instead, it’s a sort of holy metaphor, or religious talisman. You bow down to it to show your respect for Rationality and membership in the Bayesian religion.
   </span>
  </p>
  <p>
   <span style="color:#333399;">
    [2] Maybe Bayesianism is like acupuncture. It has little practical value, and its elaborate theoretical framework is nonsense; but it’s mostly harmless, and it makes people feel better about themselves, so it’s good on balance.
   </span>
  </p>
  <p>
   <span style="color:#333399;">
    [3] This seems to be the case for Bayesianism also. Leaders pepper their writing with allusions to the obscure metaphysics and math, which are only vaguely related to their actual conduct of reasoning.
   </span>
  </p>
  <p>
   <span style="color:#333399;">
    [4] It is widely noted that Bayesianism operates as a quasi-religious cult. This is not just my personal hobby-horse.
   </span>
  </p>
 </blockquote>
 <p>
  At this point Chapman notices this quote by Eliezer:
 </p>
 <blockquote>
  <p>
   <em>
    [Eliezer]:
   </em>
   <span style="color:#ff6600;">
    Let’s get it out of our systems: Bayes Bayes Bayes Bayes Bayes Bayes Bayes Bayes Bayes… The sacred syllable is meaningless, except insofar as it tells someone to apply math.
   </span>
  </p>
 </blockquote>
 <p>
  And apparently fails at reading comprehension:
 </p>
 <blockquote>
  <p>
   <em>
    [Chapman]:
   </em>
   <span style="color:#333399;">
    Right. So why
    <em>
     doesn’t
    </em>
    he get it out his system? Here
    <em>
     he’s
    </em>
    the one calling it a “sacred syllable.” Apparently he’s aware of the quasi-religious nature of what he’s doing. What’s up with that?
   </span>
  </p>
 </blockquote>
 <p>
  Who are these misguided Bayesian zealots? Did the people who accuse rationalists of being a quasi-religious cult talk to a single person who has read The Sequences? Does Champan really think that when Eliezer says “don’t be a cult,  just do math” he really means “be a cult”? We’ll never know, because when
  <span style="color:#008000;">
   <a href="http://slatestarcodex.com/2013/08/06/on-first-looking-into-chapmans-pop-bayesianism/" style="color:#008000;" target="_blank">
    Scott rebutted Chapman’s straw version of Bayesianism,
   </a>
  </span>
  Chapman suddenly
  <span style="color:#008000;">
   <a href="http://slatestarcodex.com/2013/08/06/on-first-looking-into-chapmans-pop-bayesianism/#comment-15672" style="color:#008000;" target="_blank">
    turned and wrote
   </a>
  </span>
  :
 </p>
 <blockquote>
  <p>
   <span style="color:#333399;">
    It’s because I find so much
    <em>
     right
    </em>
    with LessWrong, and that I admire its aims so much, that I’m so frustrated with its limitations and (seeming) errors. I’m afraid my careless expressions of frustration may sometimes offend. They may also baffle, because I haven’t actually offered a substantive critique (or even decided whether to do so). I apologize for both.
   </span>
  </p>
 </blockquote>
 <p>
  It’s nice to get an apology, but it would be much nicer if Chapman
  <em>
   deleted these quotes from his blog
  </em>
  . The very best rationalists are people like Scott, Kaj Sotala and Vaniver who replied on
  <span style="color:#008000;">
   <a href="http://meaningness.com/metablog/bayesianism-updating/comments" style="color:#008000;" target="_blank">
    Chapman’s blog with thoughtful, polite discussions
   </a>
  </span>
  of math and epistemology. The only fault I can find with that is that they should have said
  <em>
   “Hey David, how about you stop calling Bayesians a religious cult
   <strong>
    and then
   </strong>
   we can start talking politely about math and epistemology?”
  </em>
 </p>
 <p>
  <img alt="Thomas Bayes.png" class="size-full wp-image-10808 aligncenter" data-attachment-id="10808" data-comments-opened="1" data-image-description="" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="Thomas Bayes" data-large-file="https://putanumonit.files.wordpress.com/2016/05/thomas-bayes.png?w=574" data-medium-file="https://putanumonit.files.wordpress.com/2016/05/thomas-bayes.png?w=300" data-orig-file="https://putanumonit.files.wordpress.com/2016/05/thomas-bayes.png" data-orig-size="574,403" data-permalink="https://putanumonit.com/2016/05/17/rationality/thomas-bayes/" sizes="(max-width: 574px) 100vw, 574px" src="https://putanumonit.files.wordpress.com/2016/05/thomas-bayes.png?w=900" srcset="https://putanumonit.files.wordpress.com/2016/05/thomas-bayes.png 574w, https://putanumonit.files.wordpress.com/2016/05/thomas-bayes.png?w=150 150w, https://putanumonit.files.wordpress.com/2016/05/thomas-bayes.png?w=300 300w"/>
 </p>
 <p>
  And no matter how much David Chapman will protest that of course he didn’t mean that Scott, Kaj and Vaniver are cultists, the harm is done.
  <em>
   “cult”
  </em>
  is the first suggestion when you google
  <em>
   “LessWrong”
  </em>
  . People mock LessWrong for being obsessed with obscure nerd topics like AI safety and cryonics. Now a super-popular mainstream blogger writes thousands of words about
  <span style="color:#008000;">
   <a href="http://waitbutwhy.com/2014/10/religion-for-the-nonreligious.html" style="color:#008000;" target="_blank">
    Rationality enlightenment
   </a>
  </span>
  ,
  <span style="color:#008000;">
   <a href="http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html" style="color:#008000;" target="_blank">
    AI safety
   </a>
  </span>
  and
  <span style="color:#008000;">
   <a href="http://waitbutwhy.com/2016/03/cryonics.html" style="color:#008000;" target="_blank">
    cryonics
   </a>
  </span>
  , while fastidiously avoiding a single mention or link to LessWrong. Journalists who never read a page of The Sequences write pieces making fun of the community, one of these articles is how I discovered the site myself!
 </p>
 <p>
  Posts like David’s disparage and smear the entire community, and having actual familiarity with the people and The Sequences he should know better. The “Bayesians are a cult” meme contributed to most LessWrongers moving away from the site into their own outlets on the “Rationalist Diaspora”, or dropping out of the discourse altogether. This robs everyone of the common base of insights and language that The Sequences provide and that allow us to share ideas and learn from each other.
 </p>
 <p>
  Most damagingly, this slander pushes new people and casual readers away from LessWrong, preventing them from discovering a life-changing resource. It’s the reason why I have to spend 1,500 words discussing “postrationalists”, to keep curious readers from googling “LessWrong” and getting a hideously distorted impression.
 </p>
 <p>
  Rationality helped me
  <span style="color:#008000;">
   <a href="https://putanumonit.com/2016/02/03/015-dating_1/" style="color:#008000;" target="_blank">
    find an amazing girlfriend
   </a>
  </span>
  (more on that story later). Rationality gave me the intuition, the analysis skills and the confidence to take
  <span style="color:#008000;">
   <a href="https://putanumonit.com/2016/04/17/022-power_skeptic/" style="color:#008000;" target="_blank">
    not even scientists at their word
   </a>
  </span>
  . Rationality lets me
  <span style="color:#008000;">
   <a href="https://putanumonit.com/2016/03/23/20_nice_guys/" style="color:#008000;" target="_blank">
    keep my cool and think of bell curves
   </a>
  </span>
  when I’m caught in a culture war. Rationality gave me the wisdom to
  <span style="color:#008000;">
   <a href="https://putanumonit.com/2016/04/27/more-power-less-poverty/" style="color:#008000;" target="_blank">
    change the things I can
   </a>
  </span>
  and
  <span style="color:#008000;">
   <a href="https://putanumonit.com/2015/12/30/010-voting/" style="color:#008000;" target="_blank">
    accept the things I can’t
   </a>
  </span>
  . Rationality inspired me to
  <span style="color:#008000;">
   <a href="https://putanumonit.com/2015/11/28/005-other_path/" style="color:#008000;" target="_blank">
    write the only poem I ever have
   </a>
  </span>
  .
 </p>
 <p>
  And now you can write bad poems too. Welcome to the Rationality society, may you be less wrong tomorrow than you were today.
 </p>
 <div class="sharedaddy sd-like-enabled sd-sharing-enabled" id="jp-post-flair">
  <div class="sharedaddy sd-sharing-enabled">
   <div class="robots-nocontent sd-block sd-social sd-social-icon sd-sharing">
    <h3 class="sd-title">
     Share this:
    </h3>
    <div class="sd-content">
     <ul>
      <li class="share-facebook">
       <a class="share-facebook sd-button share-icon no-text" data-shared="sharing-facebook-9857" href="https://putanumonit.com/2016/05/17/rationality/?share=facebook" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on Facebook">
        <span>
        </span>
        <span class="sharing-screen-reader-text">
         Click to share on Facebook (Opens in new window)
        </span>
       </a>
      </li>
      <li class="share-twitter">
       <a class="share-twitter sd-button share-icon no-text" data-shared="sharing-twitter-9857" href="https://putanumonit.com/2016/05/17/rationality/?share=twitter" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on Twitter">
        <span>
        </span>
        <span class="sharing-screen-reader-text">
         Click to share on Twitter (Opens in new window)
        </span>
       </a>
      </li>
      <li class="share-pocket">
       <a class="share-pocket sd-button share-icon no-text" data-shared="" href="https://putanumonit.com/2016/05/17/rationality/?share=pocket" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on Pocket">
        <span>
        </span>
        <span class="sharing-screen-reader-text">
         Click to share on Pocket (Opens in new window)
        </span>
       </a>
      </li>
      <li class="share-reddit">
       <a class="share-reddit sd-button share-icon no-text" data-shared="" href="https://putanumonit.com/2016/05/17/rationality/?share=reddit" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on Reddit">
        <span>
        </span>
        <span class="sharing-screen-reader-text">
         Click to share on Reddit (Opens in new window)
        </span>
       </a>
      </li>
      <li class="share-tumblr">
       <a class="share-tumblr sd-button share-icon no-text" data-shared="" href="https://putanumonit.com/2016/05/17/rationality/?share=tumblr" rel="nofollow noopener noreferrer" target="_blank" title="Click to share on Tumblr">
        <span>
        </span>
        <span class="sharing-screen-reader-text">
         Click to share on Tumblr (Opens in new window)
        </span>
       </a>
      </li>
      <li class="share-email">
       <a class="share-email sd-button share-icon no-text" data-shared="" href="https://putanumonit.com/2016/05/17/rationality/?share=email" rel="nofollow noopener noreferrer" target="_blank" title="Click to email this to a friend">
        <span>
        </span>
        <span class="sharing-screen-reader-text">
         Click to email this to a friend (Opens in new window)
        </span>
       </a>
      </li>
      <li class="share-end">
      </li>
     </ul>
    </div>
   </div>
  </div>
  <div class="sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-unloaded" data-name="like-post-frame-101823629-9857-6010a8c766c25" data-src="//widgets.wp.com/likes/index.html?ver=20200826#blog_id=101823629&amp;post_id=9857&amp;origin=putanumonit.wordpress.com&amp;obj_id=101823629-9857-6010a8c766c25&amp;domain=putanumonit.com" id="like-post-wrapper-101823629-9857-6010a8c766c25">
   <h3 class="sd-title">
    Like this:
   </h3>
   <div class="likes-widget-placeholder post-likes-widget-placeholder" style="height: 55px;">
    <span class="button">
     <span>
      Like
     </span>
    </span>
    <span class="loading">
     Loading...
    </span>
   </div>
   <span class="sd-text-color">
   </span>
   <a class="sd-link-color">
   </a>
  </div>
  <div class="jp-relatedposts" id="jp-relatedposts">
   <h3 class="jp-relatedposts-headline">
    <em>
     Related
    </em>
   </h3>
  </div>
 </div>
</div>